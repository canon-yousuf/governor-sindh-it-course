"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[8635],{7044:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>n,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"module-4-vla/whisper-voice","title":"Whisper Integration","description":"Voice-to-Action with OpenAI Whisper","source":"@site/docs/05-module-4-vla/whisper-voice.md","sourceDirName":"05-module-4-vla","slug":"/module-4-vla/whisper-voice","permalink":"/physical-ai-book/docs/module-4-vla/whisper-voice","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/05-module-4-vla/whisper-voice.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Whisper Integration","description":"Voice-to-Action with OpenAI Whisper"},"sidebar":"tutorialSidebar","previous":{"title":"Nav2 (Navigation 2)","permalink":"/physical-ai-book/docs/module-3-brain/nav2"},"next":{"title":"LLM Planning","permalink":"/physical-ai-book/docs/module-4-vla/llm-planning"}}');var r=t(4848),o=t(8453);const n={sidebar_position:1,title:"Whisper Integration",description:"Voice-to-Action with OpenAI Whisper"},a="Voice-to-Action with Whisper",c={},l=[{value:"Architecture",id:"architecture",level:2},{value:"Setup",id:"setup",level:2}];function h(e){const i={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"voice-to-action-with-whisper",children:"Voice-to-Action with Whisper"})}),"\n",(0,r.jsxs)(i.p,{children:["To interact naturally with humanoids, we use ",(0,r.jsx)(i.strong,{children:"OpenAI Whisper"})," for robust speech-to-text."]}),"\n",(0,r.jsx)(i.h2,{id:"architecture",children:"Architecture"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Microphone Node"}),": Captures audio buffer."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Whisper Service"}),": Transcribes audio to text."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Intent Matcher"}),': Maps text to ROS actions (e.g., "Walk forward" -> ',(0,r.jsx)(i.code,{children:"/cmd_vel"}),")."]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"setup",children:"Setup"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-bash",children:"pip install openai-whisper\n"})}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-python",children:'import whisper\nmodel = whisper.load_model("base")\nresult = model.transcribe("audio.mp3")\nprint(result["text"])\n'})})]})}function d(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);